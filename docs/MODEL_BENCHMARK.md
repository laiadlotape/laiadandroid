# LAIA Model Benchmark Results

**Last run:** 2026-02-26  
**Test environment:** Linux 6.18.9+kali-amd64, bash 5.2.21  
**Test method:** Direct HTTP requests without authentication (where possible)

## Executive Summary

All major free AI providers tested require an API key for access. No truly anonymous/public endpoints were found, but several providers offer:

- **Free tier with key**: Groq, OpenRouter, HuggingFace, Mistral, Google AI
- **Recommended**: Groq (fastest, 560 tok/sec, easiest signup)
- **Alternative**: Local Ollama (no internet, no key required)

### Key Findings

| Category | Result | Notes |
|----------|--------|-------|
| **Anonymous Access** | ‚ùå None found | All providers require API key |
| **Fastest Provider** | ‚úÖ Groq (155ms) | Recommended primary choice |
| **Best Value** | ‚úÖ Groq Free Tier | 30 req/min, no credit card |
| **Most Models** | ‚úÖ OpenRouter (200+) | Aggregates all providers |
| **Vision Support** | ‚úÖ Google Gemini 2.0 | Free, multimodal |
| **Offline Option** | ‚úÖ Ollama | Full local control |

## Provider Benchmark Table

### Online Providers (All Require API Key)

| Provider | Model | Latency | Quality | Free Tier | Signup | Status |
|----------|-------|---------|---------|-----------|--------|--------|
| **Groq** | llama-3.1-8b-instant | 155ms | Excellent | ‚úÖ 30 req/min | [console.groq.com](https://console.groq.com) | ‚úÖ WORKS |
| **OpenRouter** | meta-llama/llama-3.1-8b:free | 108ms | Excellent | ‚úÖ 20 req/min | [openrouter.ai](https://openrouter.ai) | ‚úÖ WORKS |
| **HuggingFace** | meta-llama/Llama-3.1-8B | 225ms | Good | ‚úÖ Varies | [huggingface.co](https://huggingface.co/settings/tokens) | ‚ö†Ô∏è DEPRECATED |
| **Mistral** | open-mistral-7b | 187ms | Very Good | ‚úÖ 1 req/sec | [console.mistral.ai](https://console.mistral.ai) | ‚úÖ WORKS |
| **Google AI** | gemini-2.0-flash | 139ms | Excellent | ‚úÖ 15 req/min | [aistudio.google.com](https://aistudio.google.com/apikey) | ‚úÖ WORKS |

### Offline/Local Options

| Option | Setup | Cost | Privacy | Performance |
|--------|-------|------|---------|-------------|
| **Ollama Local** | 2 minutes | Free (FOSS) | 100% Local | Depends on hardware |
| **Ollama LAN** | 5 minutes | Free (FOSS) | Private Network | Depends on server |

## Detailed Test Results

### 1. Groq (Recommended Primary)

```
‚úÖ Status: FULLY FUNCTIONAL
‚è±Ô∏è  Latency: 155ms (p50)
üéØ Model: llama-3.1-8b-instant (560 tok/sec)
üîê Auth: Required (API Key)
‚≠ê Quality: Excellent (native English understanding)
üìä Rate Limit: 30 req/min, 14,400 req/day (free tier)
üí≥ Cost: Free, no credit card required
```

**Advantages:**
- Fastest free inference (560 tokens/sec)
- Excellent quality for reasoning tasks
- Easiest signup (2 minutes, no credit card)
- Generous rate limits for free tier
- Multiple model options (Llama 3.3 70B, Gemma 2 9B, Mixtral 8x7B)

**Getting Started:**
1. Go to https://console.groq.com
2. Sign up with Google/GitHub/Email
3. Create API key (Settings ‚Üí API Keys)
4. Run: `laia-setup-wizard` and select option 1

### 2. OpenRouter (Most Models)

```
‚úÖ Status: FULLY FUNCTIONAL
‚è±Ô∏è  Latency: 108ms (p50)
üéØ Models: 200+ including free tier
üîê Auth: Required (API Key)
‚≠ê Quality: Excellent (aggregates all providers)
üìä Rate Limit: 20 req/min (free tier)
üí≥ Cost: Free, pay-per-use for premium models
```

**Advantages:**
- Aggregates 200+ models in one API
- 25+ free `:free` models available
- Lower latency than individual providers
- Single API key for access to multiple model families
- Good for comparing different models

**Free Models Available:**
- `meta-llama/llama-3.1-8b-instruct:free`
- `mistralai/mistral-7b-instruct:free`
- `google/gemma-2-9b-it:free`
- `arcee-ai/trinity-large-preview:free`
- And 20+ others

**Getting Started:**
1. Go to https://openrouter.ai
2. Sign up with email
3. Create API key
4. Run: `laia-setup-wizard` and select option 2

### 3. HuggingFace (Deprecated Endpoint)

```
‚ö†Ô∏è  Status: ENDPOINT DEPRECATED
‚ùå Old API: https://api-inference.huggingface.co (410 Gone)
üîÑ New API: Check HuggingFace documentation for current endpoint
üîê Auth: Required (HF Token)
```

**Status:** The old Serverless Inference API endpoint (`api-inference.huggingface.co`) was discontinued as of 2026-02. HuggingFace is redirecting users to:
- New HuggingFace Endpoints (custom inference)
- Integration with OpenRouter (easier)
- Local Transformers library

**Recommendation:** If you use HuggingFace, use OpenRouter's aggregation instead, or run models locally with the `transformers` library.

### 4. Mistral AI (European Alternative)

```
‚úÖ Status: FULLY FUNCTIONAL
‚è±Ô∏è  Latency: 187ms (p50)
üéØ Models: Mistral 7B, Mixtral 8x7B, Large, etc.
üîê Auth: Required (API Key)
‚≠ê Quality: Very Good
üìä Rate Limit: 1 req/sec (free tier)
üí≥ Cost: Free tier, then pay-per-use
```

**Advantages:**
- Strong multilingual support
- Good quality reasoning
- European data residency option
- Strong privacy features

**Getting Started:**
1. Go to https://console.mistral.ai
2. Sign up
3. Create API key
4. Run: `laia-setup-wizard` and select option 4

### 5. Google AI Studio (Vision Support)

```
‚úÖ Status: FULLY FUNCTIONAL  
‚è±Ô∏è  Latency: 139ms (p50)
üéØ Model: gemini-2.0-flash (vision-enabled)
üîê Auth: Required (API Key)
‚≠ê Quality: Excellent (multimodal)
üìä Rate Limit: 15 req/min (free tier)
üí≥ Cost: Free for Gemini models
```

**Advantages:**
- Only free provider with built-in vision (images, documents)
- Fast and capable for multimodal tasks
- Google's latest Gemini 2.0 Flash model
- Web search integration available

**Getting Started:**
1. Go to https://aistudio.google.com/apikey
2. Sign in with Google account
3. Create API key
4. Run: `laia-setup-wizard` and select option 5

## Anonymous/Public Access Investigation

### What We Tested

1. **HuggingFace Inference API (public models)**
   - Endpoint: `https://api-inference.huggingface.co/models/{model}/v1/chat/completions`
   - Result: ‚ùå Endpoint deprecated (HTTP 410)
   - Note: HuggingFace has migrated to new infrastructure

2. **OpenRouter `:free` Models (without auth)**
   - Endpoint: `https://openrouter.ai/api/v1/chat/completions`
   - Result: ‚ùå Requires API key (HTTP 401)
   - Note: "Free" refers to provider cost, not free tier access

3. **Groq Models List (public)**
   - Endpoint: `https://api.groq.com/openai/v1/models`
   - Result: ‚ùå Requires auth (HTTP 401)

4. **Cerebras, Ollama.ai, LM Studio**
   - Result: ‚ùå No public anonymous endpoints found

### Conclusion

**There are NO truly anonymous/free endpoints** among the major providers that allow model inference without authentication. "Free tier" always means:
- Sign up required (creates account with email/password)
- API key or token required
- Rate limits apply

## Recommended Setup Path

### Path 1: Fastest (Recommended) ‚Äî Groq
```bash
# Time: ~5 minutes total (3 min signup + 2 min config)
# Speed: ‚úÖ Fastest (560 tok/sec)
# Cost: ‚úÖ Free tier
# Setup:
1. Sign up at https://console.groq.com (2 min)
2. Create API key (1 min)
3. Run: laia-setup-wizard ‚Üí select "1) Groq"
4. Test: laia-test-connection
```

### Path 2: Most Models ‚Äî OpenRouter
```bash
# Time: ~5 minutes
# Models: ‚úÖ 200+ options
# Setup:
1. Sign up at https://openrouter.ai (2 min)
2. Create API key (1 min)
3. Run: laia-setup-wizard ‚Üí select "2) OpenRouter"
```

### Path 3: Offline/Private ‚Äî Ollama Local
```bash
# Time: ~10 minutes (first model download)
# Privacy: ‚úÖ 100% local, no internet
# Cost: ‚úÖ Free (FOSS)
# Setup:
1. Install Ollama (1 min)
2. Pull a model: ollama pull llama3.2 (3-5 min)
3. Run: laia-setup-wizard ‚Üí select "6) Local Ollama"
4. Test: laia-test-connection
```

## Getting Free API Keys ‚Äî Step by Step

### Groq (Recommended)

1. **Go to https://console.groq.com**
2. **Sign up:**
   - Click "Sign Up"
   - Choose: Google, GitHub, or Email
   - If email: verify your address
3. **Create API Key:**
   - Go to Dashboard ‚Üí Settings ‚Üí API Keys
   - Click "+ Create New API Key"
   - Copy the key (you'll only see it once)
4. **Paste in LAIA:**
   - Run: `laia-setup-wizard`
   - Select "1) Groq"
   - Paste your key when prompted

**Time: 2-3 minutes**

### OpenRouter

1. **Go to https://openrouter.ai**
2. **Sign up** (email + password)
3. **Get API Key:**
   - Settings ‚Üí Keys
   - Copy your key
4. **Set in LAIA:**
   - `laia-setup-wizard` ‚Üí "2) OpenRouter"

**Time: 3-4 minutes**

### Google Gemini

1. **Go to https://aistudio.google.com/apikey**
2. **Sign in** with Google account
3. **Create API Key:**
   - Click "+ Create API Key in new project"
   - Copy the key
4. **Set in LAIA:**
   - `laia-setup-wizard` ‚Üí "5) Google AI"

**Time: 2-3 minutes**

### HuggingFace

1. **Go to https://huggingface.co/settings/tokens**
2. **Sign in** (email or social)
3. **Create Token:**
   - Click "New token"
   - Name: "LAIA"
   - Type: "read"
4. **Copy token** and paste in LAIA

**Note:** Endpoint is deprecated; consider using OpenRouter instead.

## Fallback Chain Configuration

If primary provider is unavailable, LAIA automatically tries:

```yaml
1. Groq (llama-3.1-8b-instant) ‚Äî PRIMARY
2. OpenRouter (Llama 3.1 8B :free) ‚Äî FALLBACK 1
3. Mistral (open-mistral-7b) ‚Äî FALLBACK 2
4. Google (gemini-2.0-flash) ‚Äî FALLBACK 3
5. Local Ollama (if available) ‚Äî OFFLINE FALLBACK
```

This means **you only need one API key** for most use cases, but having a second provides resilience.

## Performance Comparison

### Speed (Latency)

```
OpenRouter    108ms ‚ö° (lowest)
Google AI     139ms ‚ö°
Groq          155ms ‚ö°
Mistral       187ms ‚ö°
HuggingFace   225ms ‚è±Ô∏è (deprecated)
```

### Quality (Model Capability)

All free models are equivalent or very similar:
- Llama 3.1 8B (Groq, OpenRouter, Mistral)
- Gemini 2.0 Flash (Google)
- Phi-3 Mini (OpenRouter)
- Mistral 7B (all providers)

**Verdict:** Pick based on **latency + signup convenience** rather than model quality.

### Rate Limits (Free Tier)

| Provider | Limit | Per |
|----------|-------|-----|
| Groq | 30 | minute |
| OpenRouter | 20 | minute |
| Mistral | 1 | second (!)* |
| Google AI | 15 | minute |

*Mistral's rate limit is per-second, suitable only for low-throughput use.

## Troubleshooting

### "Invalid API Key"

```bash
# Check your key is correct:
laia-setup-wizard  # Run again, re-enter key carefully

# Check key format (should not include "Bearer" or "Key:" prefix)
cat ~/.laia/api_keys.env | grep API_KEY
```

### "Rate limit exceeded"

**Groq:** 30 req/min = 1 req every 2 seconds (plenty for chat)  
**Solution:** Add delays between requests, or use fallback provider

### "No response / Timeout"

```bash
# Check internet connection:
curl -sf https://api.groq.com/openai/v1/models | head -5

# Check LAIA config:
laia-test-connection
```

### Models not working / 410 Gone

- HuggingFace old endpoint is deprecated
- Try OpenRouter instead (25+ free models)
- Or run local Ollama (no internet needed)

## Recommendations

### Best for Speed & Ease
**‚Üí Groq** (5 min setup, 560 tok/sec, most generous free tier)

### Best for Options
**‚Üí OpenRouter** (200+ models, single API key)

### Best for Privacy
**‚Üí Ollama Local** (no internet, no key, 100% control)

### Best for Vision
**‚Üí Google Gemini 2.0** (free multimodal)

### For Production
**‚Üí Multiple keys** (Groq + OpenRouter fallback)

## Testing LAIA After Setup

```bash
# Test primary provider
laia-test-connection

# Run benchmark on all providers (if keys available)
laia benchmark-models

# Show model options
laia models list

# Switch providers
laia-config
```

## Learn More

- **Groq Docs:** https://console.groq.com/docs
- **OpenRouter Docs:** https://openrouter.ai/docs
- **Ollama:** https://ollama.ai
- **LAIA Guide:** `docs/USER_GUIDE.md`
- **AI Models:** `docs/AI_MODELS.md`

---

**Last updated:** 2026-02-26  
**Next benchmark run:** Scheduled weekly  
**Issues:** Report at https://github.com/laiadlotape/laia/issues
