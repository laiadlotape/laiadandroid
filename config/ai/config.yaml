# LAIA Active AI Configuration
# Generated by laia-setup-wizard or laia-config
# Edit manually or via GUI: laia-config
#
# Tested: 2026-02-26
# Summary: All online providers require API key (no anonymous access found)
# Recommended: Groq (fastest) or local Ollama (no internet required)

mode: online

online:
  provider: groq
  model: llama-3.1-8b-instant
  fallback_chain:
    - provider: groq
      model: llama-3.1-8b-instant
      requires_key: true
      note: "Fastest free inference, recommended primary choice"
    - provider: openrouter
      model: "meta-llama/llama-3.1-8b-instruct:free"
      requires_key: true
      note: "Aggregates 200+ models"
    - provider: mistral
      model: open-mistral-7b
      requires_key: true
      note: "European AI with good multilingual support"
    - provider: google
      model: gemini-2.0-flash
      requires_key: true
      note: "Fast, capable, vision-enabled"

local:
  enabled: false
  host: "127.0.0.1"
  port: 11434
  model: "gemma3:4b"
  note: "No internet required, runs models locally"

lan:
  enabled: false
  host: ""
  port: 11434
  model: "gemma3:4b"
  note: "Connect to Ollama on your network"

openwebui:
  enabled: true
  port: 3000
  bind: "127.0.0.1"

openclaw:
  mode: "online"
